{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4269f098-502a-4414-b70c-01ed3e299cfb",
   "metadata": {},
   "source": [
    "#### Project 2 Facial Recognition  \n",
    "#### Author: Brian Reppeto 1/26/2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3707358a-2c29-4ad4-b9f5-4e61ad54eb4f",
   "metadata": {},
   "source": [
    "### Import necessary libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebffb2da-5d96-4f3b-9ea6-a55b85dffdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "from deepface import DeepFace\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200c3377-72a6-4cc3-adb1-ce1c24ce3fab",
   "metadata": {},
   "source": [
    "### Specify the paths for reference images, input images (where faces will be detected), and output folder (where matched faces will be saved)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed489867-c078-4466-990b-ad73e02e4e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths of images\n",
    "\n",
    "reference_folder = r\"C:\\Users\\brepp\\OneDrive\\Desktop\\Photos\\ReferenceImages\"\n",
    "input_folder = r\"C:\\Users\\brepp\\OneDrive\\Desktop\\Photos\\Brian\\iCloud Photos\"\n",
    "output_folder = r\"C:\\Users\\brepp\\OneDrive\\Desktop\\ExtractedFaces\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38502383-e789-4cdb-9c8c-4608a7d6c01a",
   "metadata": {},
   "source": [
    "###  Check if my face matches any of the reference images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9811b2-2a24-4f10-b339-86b5032adf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to verify if my face matches any of the reference images\n",
    "\n",
    "def is_my_face(reference_folder, test_face, threshold=0.65):\n",
    "    temp_face_path = \"temp_face.jpg\" # create temp file \n",
    "    cv2.imwrite(temp_face_path, test_face)\n",
    "    \n",
    "    try:  # try except block \n",
    "        best_similarity = 0 # keep track of best score\n",
    "        predictions = []\n",
    "        ground_truth = []\n",
    "        \n",
    "        for reference_image_name in os.listdir(reference_folder):  #  loop thru ref images skip non-image Files\n",
    "            reference_image_path = os.path.join(reference_folder, reference_image_name)\n",
    "            if not reference_image_name.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "                continue\n",
    "\n",
    "            try: #  face comparison - compare ref image to test image to get simularity score\n",
    "                result = DeepFace.verify(\n",
    "                    img1_path=reference_image_path,\n",
    "                    img2_path=temp_face_path,\n",
    "                    model_name=\"Facenet\",\n",
    "                    enforce_detection=False\n",
    "                )\n",
    "                similarity = 1 - result[\"distance\"]  # convert distance to similarity # lower means more similar\n",
    "                predictions.append(1 if similarity > threshold else 0)\n",
    "                ground_truth.append(1)  # assuming all reference images are correct matches\n",
    "                best_similarity = max(best_similarity, similarity)\n",
    "            except Exception as e:\n",
    "                print(f\"Error comparing with {reference_image_name}: {e}\") # handle errors during processing\n",
    "        # compute metrics\n",
    "        if predictions:\n",
    "            precision = precision_score(ground_truth, predictions)\n",
    "            recall = recall_score(ground_truth, predictions)\n",
    "            f1 = f1_score(ground_truth, predictions)\n",
    "            tn, fp, fn, tp = confusion_matrix(ground_truth, predictions).ravel()\n",
    "            far = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "            frr = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "            \n",
    "            print(f\"Precision: {precision:.2f}\") # print performance metrics\n",
    "            print(f\"Recall: {recall:.2f}\")\n",
    "            print(f\"F1-score: {f1:.2f}\")\n",
    "            print(f\"False Acceptance Rate (FAR): {far:.2f}\")\n",
    "            print(f\"False Rejection Rate (FRR): {frr:.2f}\")\n",
    "        \n",
    "        return best_similarity > threshold # \n",
    "    except Exception as e:\n",
    "        print(f\"Error during face verification: {e}\")\n",
    "        return False\n",
    "    finally:\n",
    "        if os.path.exists(temp_face_path): # remove temp images\n",
    "            os.remove(temp_face_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f905a399-09d0-4611-8b61-c9623d2f20ac",
   "metadata": {},
   "source": [
    "###  Function to detect and crop faces from an image using OpenCV's Haar cascade classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eacf72f-32db-49cb-9a47-90ed0b0ee8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to detect and crop faces using OpenCV\n",
    "\n",
    "def detect_faces(image):\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\") #  load Haar cascade classifier for frontal face detection using OpenCV\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) # convert image to grey scale\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30)) # detect face in images\n",
    "    cropped_faces = [image[y:y+h, x:x+w] for (x, y, w, h) in faces] # ret \n",
    "    return cropped_faces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018e9c27-bc64-419c-8f96-092807c056e2",
   "metadata": {},
   "source": [
    "###  Extract and save images of my face and compare to reference images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f048b90d-3bfc-4c6c-b9a7-e7cf4edabad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to process images and evaluate performance\n",
    "\n",
    "def extract_my_faces_from_folder(reference_folder, input_folder, output_folder, threshold=0.65):\n",
    "    os.makedirs(output_folder, exist_ok=True) # create out put folder\n",
    "     ground_truth_labels = []\n",
    "    predictions = []\n",
    "    \n",
    "    for file_name in os.listdir(input_folder): # loop over images\n",
    "        if file_name.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "            image_path = os.path.join(input_folder, file_name) # load each image\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                continue\n",
    "\n",
    "            faces = detect_faces(image) # detect faces in the images\n",
    "            for i, face in enumerate(faces): # loop over each face and compare to ref. image\n",
    "                is_match = is_my_face(reference_folder, face, threshold)\n",
    "                predictions.append(1 if is_match else 0)\n",
    "                ground_truth_labels.append(1)  \n",
    "                \n",
    "                if is_match: # save matched faces to folder...  This is how I calculated my errors \n",
    "                    output_path = os.path.join(output_folder, f\"{os.path.splitext(file_name)[0]}_face_{i}.jpg\")\n",
    "                    cv2.imwrite(output_path, face)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cec677b-fb46-453c-ab6b-51f2745e9a7e",
   "metadata": {},
   "source": [
    "### Call extract_my_faces_from_folder to run the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44607af-762b-4697-94e3-82bf84c84b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the extraction and evaluation\n",
    "\n",
    "extract_my_faces_from_folder(reference_folder, input_folder, output_folder, threshold=0.65)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce37cf1-75f7-45de-b89b-95aa7ef0f5ab",
   "metadata": {},
   "source": [
    "### Plot Correlation Matrix of the changes in the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be64041f-ca91-4cd6-9e0d-c2f6972fed2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the thresholds used along with the correct True Positive, True Negative, False Positives, and False Negatives\n",
    "# plotting the results\n",
    "\n",
    "data = {\n",
    "    'Threshold':  [6, 4, 7, 7.5, 6.5, 6.5, 6, 6, 6, 7],\n",
    "    'TPR_counts': [63,162,93, 94, 30, 121,172,189,227,189],\n",
    "    'FPR_counts': [1, 59, 0,  0,  0,   1,   0,   3,   30,  0],\n",
    "    'Ref_Photos': [5,  5,  5,  5,  5,  10,  20,  20,  30,  30]\n",
    "}\n",
    "\n",
    "# build the DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# calc the correlation matrix\n",
    "corr_matrix = df.corr()\n",
    "\n",
    "# plot the heatmap\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title(\"Correlation Matrix Heatmap\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae0f4e0-5fbc-4882-9728-aa1905ae2e58",
   "metadata": {},
   "source": [
    "### Scatter Plot with regression line for the relationship between the count of ref. photos to total accuracy count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71dea33-9ad5-4fbc-b4b9-9165d0ea724e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref images used and total captured faces\n",
    "\n",
    "data = {\n",
    "    'Ref_Photos': [5,  5,   5,  5,  5,  10,  20,  20,  30,  30],\n",
    "    'TPR_counts': [63,162, 93, 94, 30, 121,172,189,227,189]\n",
    "}\n",
    "\n",
    "# create dataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# plot a scatter with regression line\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.regplot(data=df, x='Ref_Photos', y='TPR_counts', ci=None, scatter_kws={'s':80})\n",
    "\n",
    "plt.title(\"Scatter Plot with Regression: Ref_Photos vs. TPR_counts\")\n",
    "plt.xlabel(\"Number of Reference Photos\")\n",
    "plt.ylabel(\"Positive Detections (TPR_counts)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
