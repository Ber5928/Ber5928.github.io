{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70247de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f4e7739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 101766 entries, 0 to 101765\n",
      "Data columns (total 50 columns):\n",
      " #   Column                    Non-Null Count   Dtype \n",
      "---  ------                    --------------   ----- \n",
      " 0   encounter_id              101766 non-null  int64 \n",
      " 1   patient_nbr               101766 non-null  int64 \n",
      " 2   race                      101766 non-null  object\n",
      " 3   gender                    101766 non-null  object\n",
      " 4   age                       101766 non-null  object\n",
      " 5   weight                    101766 non-null  object\n",
      " 6   admission_type_id         101766 non-null  int64 \n",
      " 7   discharge_disposition_id  101766 non-null  int64 \n",
      " 8   admission_source_id       101766 non-null  int64 \n",
      " 9   time_in_hospital          101766 non-null  int64 \n",
      " 10  payer_code                101766 non-null  object\n",
      " 11  medical_specialty         101766 non-null  object\n",
      " 12  num_lab_procedures        101766 non-null  int64 \n",
      " 13  num_procedures            101766 non-null  int64 \n",
      " 14  num_medications           101766 non-null  int64 \n",
      " 15  number_outpatient         101766 non-null  int64 \n",
      " 16  number_emergency          101766 non-null  int64 \n",
      " 17  number_inpatient          101766 non-null  int64 \n",
      " 18  diag_1                    101766 non-null  object\n",
      " 19  diag_2                    101766 non-null  object\n",
      " 20  diag_3                    101766 non-null  object\n",
      " 21  number_diagnoses          101766 non-null  int64 \n",
      " 22  max_glu_serum             5346 non-null    object\n",
      " 23  A1Cresult                 17018 non-null   object\n",
      " 24  metformin                 101766 non-null  object\n",
      " 25  repaglinide               101766 non-null  object\n",
      " 26  nateglinide               101766 non-null  object\n",
      " 27  chlorpropamide            101766 non-null  object\n",
      " 28  glimepiride               101766 non-null  object\n",
      " 29  acetohexamide             101766 non-null  object\n",
      " 30  glipizide                 101766 non-null  object\n",
      " 31  glyburide                 101766 non-null  object\n",
      " 32  tolbutamide               101766 non-null  object\n",
      " 33  pioglitazone              101766 non-null  object\n",
      " 34  rosiglitazone             101766 non-null  object\n",
      " 35  acarbose                  101766 non-null  object\n",
      " 36  miglitol                  101766 non-null  object\n",
      " 37  troglitazone              101766 non-null  object\n",
      " 38  tolazamide                101766 non-null  object\n",
      " 39  examide                   101766 non-null  object\n",
      " 40  citoglipton               101766 non-null  object\n",
      " 41  insulin                   101766 non-null  object\n",
      " 42  glyburide-metformin       101766 non-null  object\n",
      " 43  glipizide-metformin       101766 non-null  object\n",
      " 44  glimepiride-pioglitazone  101766 non-null  object\n",
      " 45  metformin-rosiglitazone   101766 non-null  object\n",
      " 46  metformin-pioglitazone    101766 non-null  object\n",
      " 47  change                    101766 non-null  object\n",
      " 48  diabetesMed               101766 non-null  object\n",
      " 49  readmitted                101766 non-null  object\n",
      "dtypes: int64(13), object(37)\n",
      "memory usage: 38.8+ MB\n",
      "None\n",
      "       encounter_id   patient_nbr  admission_type_id  \\\n",
      "count  1.017660e+05  1.017660e+05      101766.000000   \n",
      "mean   1.652016e+08  5.433040e+07           2.024006   \n",
      "std    1.026403e+08  3.869636e+07           1.445403   \n",
      "min    1.252200e+04  1.350000e+02           1.000000   \n",
      "25%    8.496119e+07  2.341322e+07           1.000000   \n",
      "50%    1.523890e+08  4.550514e+07           1.000000   \n",
      "75%    2.302709e+08  8.754595e+07           3.000000   \n",
      "max    4.438672e+08  1.895026e+08           8.000000   \n",
      "\n",
      "       discharge_disposition_id  admission_source_id  time_in_hospital  \\\n",
      "count             101766.000000        101766.000000     101766.000000   \n",
      "mean                   3.715642             5.754437          4.395987   \n",
      "std                    5.280166             4.064081          2.985108   \n",
      "min                    1.000000             1.000000          1.000000   \n",
      "25%                    1.000000             1.000000          2.000000   \n",
      "50%                    1.000000             7.000000          4.000000   \n",
      "75%                    4.000000             7.000000          6.000000   \n",
      "max                   28.000000            25.000000         14.000000   \n",
      "\n",
      "       num_lab_procedures  num_procedures  num_medications  number_outpatient  \\\n",
      "count       101766.000000   101766.000000    101766.000000      101766.000000   \n",
      "mean            43.095641        1.339730        16.021844           0.369357   \n",
      "std             19.674362        1.705807         8.127566           1.267265   \n",
      "min              1.000000        0.000000         1.000000           0.000000   \n",
      "25%             31.000000        0.000000        10.000000           0.000000   \n",
      "50%             44.000000        1.000000        15.000000           0.000000   \n",
      "75%             57.000000        2.000000        20.000000           0.000000   \n",
      "max            132.000000        6.000000        81.000000          42.000000   \n",
      "\n",
      "       number_emergency  number_inpatient  number_diagnoses  \n",
      "count     101766.000000     101766.000000     101766.000000  \n",
      "mean           0.197836          0.635566          7.422607  \n",
      "std            0.930472          1.262863          1.933600  \n",
      "min            0.000000          0.000000          1.000000  \n",
      "25%            0.000000          0.000000          6.000000  \n",
      "50%            0.000000          0.000000          8.000000  \n",
      "75%            0.000000          1.000000          9.000000  \n",
      "max           76.000000         21.000000         16.000000  \n",
      "Value counts of the 'readmitted' column before transformation:\n",
      "readmitted\n",
      "2    54864\n",
      "1    35545\n",
      "0    11357\n",
      "Name: count, dtype: int64\n",
      "Value counts of the target variable (y):\n",
      "readmitted\n",
      "1    54864\n",
      "0    46902\n",
      "Name: count, dtype: int64\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.61      0.63      9381\n",
      "           1       0.68      0.73      0.70     10973\n",
      "\n",
      "    accuracy                           0.67     20354\n",
      "   macro avg       0.67      0.67      0.67     20354\n",
      "weighted avg       0.67      0.67      0.67     20354\n",
      "\n",
      "Confusion Matrix:\n",
      "[[5714 3667]\n",
      " [3012 7961]]\n",
      "ROC AUC Score:\n",
      "0.7340286450700532\n",
      "Model Accuracy: 0.67\n",
      "Random Guessing Accuracy: 0.54\n",
      "Improvement Factor: 1.25\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('diabetic_data.csv')\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(data.info())\n",
    "print(data.describe())\n",
    "\n",
    "# Data preprocessing\n",
    "# Remove columns with a single unique value\n",
    "data = data[[col for col in data.columns if data[col].nunique() > 1]]\n",
    "\n",
    "# Handle missing values if necessary\n",
    "data.replace('?', np.nan, inplace=True)\n",
    "data.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_columns = data.select_dtypes(include=['object']).columns\n",
    "label_encoders = {}\n",
    "for column in categorical_columns:\n",
    "    label_encoders[column] = LabelEncoder()\n",
    "    data[column] = label_encoders[column].fit_transform(data[column])\n",
    "\n",
    "# Print the value counts of the 'readmitted' column before transformation\n",
    "print(\"Value counts of the 'readmitted' column before transformation:\")\n",
    "print(data['readmitted'].value_counts())\n",
    "\n",
    "# Define the feature matrix and target vector\n",
    "X = data.drop(columns=['readmitted'])\n",
    "# Map readmitted column to binary values: 1 for '<30', 0 otherwise\n",
    "y = data['readmitted'].map(lambda x: 1 if x == 2 else 0)\n",
    "\n",
    "# Ensure that the target variable has both classes\n",
    "print(\"Value counts of the target variable (y):\")\n",
    "print(y.value_counts())\n",
    "\n",
    "# Check if the target variable has at least two classes\n",
    "if y.nunique() < 2:\n",
    "    raise ValueError(\"The target variable 'y' must have at least two classes. Please check the preprocessing steps.\")\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize the gradient boosting classifier\n",
    "gbc = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'max_depth': [3, 4, 5]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=gbc, param_grid=param_grid, cv=5, n_jobs=-1, scoring='roc_auc')\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Best model\n",
    "best_gbc = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = best_gbc.predict(X_test_scaled)\n",
    "y_pred_proba = best_gbc.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"ROC AUC Score:\")\n",
    "print(roc_auc_score(y_test, y_pred_proba))\n",
    "\n",
    "# Model performance\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "random_accuracy = np.mean(y_test)\n",
    "improvement_factor = accuracy / random_accuracy\n",
    "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Random Guessing Accuracy: {random_accuracy:.2f}\")\n",
    "print(f\"Improvement Factor: {improvement_factor:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ace7e307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 101766 entries, 0 to 101765\n",
      "Data columns (total 50 columns):\n",
      " #   Column                    Non-Null Count   Dtype \n",
      "---  ------                    --------------   ----- \n",
      " 0   encounter_id              101766 non-null  int64 \n",
      " 1   patient_nbr               101766 non-null  int64 \n",
      " 2   race                      101766 non-null  object\n",
      " 3   gender                    101766 non-null  object\n",
      " 4   age                       101766 non-null  object\n",
      " 5   weight                    101766 non-null  object\n",
      " 6   admission_type_id         101766 non-null  int64 \n",
      " 7   discharge_disposition_id  101766 non-null  int64 \n",
      " 8   admission_source_id       101766 non-null  int64 \n",
      " 9   time_in_hospital          101766 non-null  int64 \n",
      " 10  payer_code                101766 non-null  object\n",
      " 11  medical_specialty         101766 non-null  object\n",
      " 12  num_lab_procedures        101766 non-null  int64 \n",
      " 13  num_procedures            101766 non-null  int64 \n",
      " 14  num_medications           101766 non-null  int64 \n",
      " 15  number_outpatient         101766 non-null  int64 \n",
      " 16  number_emergency          101766 non-null  int64 \n",
      " 17  number_inpatient          101766 non-null  int64 \n",
      " 18  diag_1                    101766 non-null  object\n",
      " 19  diag_2                    101766 non-null  object\n",
      " 20  diag_3                    101766 non-null  object\n",
      " 21  number_diagnoses          101766 non-null  int64 \n",
      " 22  max_glu_serum             5346 non-null    object\n",
      " 23  A1Cresult                 17018 non-null   object\n",
      " 24  metformin                 101766 non-null  object\n",
      " 25  repaglinide               101766 non-null  object\n",
      " 26  nateglinide               101766 non-null  object\n",
      " 27  chlorpropamide            101766 non-null  object\n",
      " 28  glimepiride               101766 non-null  object\n",
      " 29  acetohexamide             101766 non-null  object\n",
      " 30  glipizide                 101766 non-null  object\n",
      " 31  glyburide                 101766 non-null  object\n",
      " 32  tolbutamide               101766 non-null  object\n",
      " 33  pioglitazone              101766 non-null  object\n",
      " 34  rosiglitazone             101766 non-null  object\n",
      " 35  acarbose                  101766 non-null  object\n",
      " 36  miglitol                  101766 non-null  object\n",
      " 37  troglitazone              101766 non-null  object\n",
      " 38  tolazamide                101766 non-null  object\n",
      " 39  examide                   101766 non-null  object\n",
      " 40  citoglipton               101766 non-null  object\n",
      " 41  insulin                   101766 non-null  object\n",
      " 42  glyburide-metformin       101766 non-null  object\n",
      " 43  glipizide-metformin       101766 non-null  object\n",
      " 44  glimepiride-pioglitazone  101766 non-null  object\n",
      " 45  metformin-rosiglitazone   101766 non-null  object\n",
      " 46  metformin-pioglitazone    101766 non-null  object\n",
      " 47  change                    101766 non-null  object\n",
      " 48  diabetesMed               101766 non-null  object\n",
      " 49  readmitted                101766 non-null  object\n",
      "dtypes: int64(13), object(37)\n",
      "memory usage: 38.8+ MB\n",
      "None\n",
      "       encounter_id   patient_nbr  admission_type_id  \\\n",
      "count  1.017660e+05  1.017660e+05      101766.000000   \n",
      "mean   1.652016e+08  5.433040e+07           2.024006   \n",
      "std    1.026403e+08  3.869636e+07           1.445403   \n",
      "min    1.252200e+04  1.350000e+02           1.000000   \n",
      "25%    8.496119e+07  2.341322e+07           1.000000   \n",
      "50%    1.523890e+08  4.550514e+07           1.000000   \n",
      "75%    2.302709e+08  8.754595e+07           3.000000   \n",
      "max    4.438672e+08  1.895026e+08           8.000000   \n",
      "\n",
      "       discharge_disposition_id  admission_source_id  time_in_hospital  \\\n",
      "count             101766.000000        101766.000000     101766.000000   \n",
      "mean                   3.715642             5.754437          4.395987   \n",
      "std                    5.280166             4.064081          2.985108   \n",
      "min                    1.000000             1.000000          1.000000   \n",
      "25%                    1.000000             1.000000          2.000000   \n",
      "50%                    1.000000             7.000000          4.000000   \n",
      "75%                    4.000000             7.000000          6.000000   \n",
      "max                   28.000000            25.000000         14.000000   \n",
      "\n",
      "       num_lab_procedures  num_procedures  num_medications  number_outpatient  \\\n",
      "count       101766.000000   101766.000000    101766.000000      101766.000000   \n",
      "mean            43.095641        1.339730        16.021844           0.369357   \n",
      "std             19.674362        1.705807         8.127566           1.267265   \n",
      "min              1.000000        0.000000         1.000000           0.000000   \n",
      "25%             31.000000        0.000000        10.000000           0.000000   \n",
      "50%             44.000000        1.000000        15.000000           0.000000   \n",
      "75%             57.000000        2.000000        20.000000           0.000000   \n",
      "max            132.000000        6.000000        81.000000          42.000000   \n",
      "\n",
      "       number_emergency  number_inpatient  number_diagnoses  \n",
      "count     101766.000000     101766.000000     101766.000000  \n",
      "mean           0.197836          0.635566          7.422607  \n",
      "std            0.930472          1.262863          1.933600  \n",
      "min            0.000000          0.000000          1.000000  \n",
      "25%            0.000000          0.000000          6.000000  \n",
      "50%            0.000000          0.000000          8.000000  \n",
      "75%            0.000000          1.000000          9.000000  \n",
      "max           76.000000         21.000000         16.000000  \n",
      "Value counts of the 'readmitted' column before transformation:\n",
      "readmitted\n",
      "2    54864\n",
      "1    35545\n",
      "0    11357\n",
      "Name: count, dtype: int64\n",
      "Value counts of the target variable (y):\n",
      "readmitted\n",
      "1    54864\n",
      "0    46902\n",
      "Name: count, dtype: int64\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.61      0.63      9381\n",
      "           1       0.68      0.73      0.70     10973\n",
      "\n",
      "    accuracy                           0.67     20354\n",
      "   macro avg       0.67      0.67      0.67     20354\n",
      "weighted avg       0.67      0.67      0.67     20354\n",
      "\n",
      "Confusion Matrix:\n",
      "[[5714 3667]\n",
      " [3012 7961]]\n",
      "ROC AUC Score:\n",
      "0.7340286450700532\n",
      "Model Accuracy: 0.67\n",
      "Random Guessing Accuracy: 0.54\n",
      "Improvement Factor: 1.25\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('diabetic_data.csv')\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(data.info())\n",
    "print(data.describe())\n",
    "\n",
    "# Data preprocessing\n",
    "# Remove columns with a single unique value\n",
    "data = data[[col for col in data.columns if data[col].nunique() > 1]]\n",
    "\n",
    "# Handle missing values\n",
    "data.replace('?', np.nan, inplace=True)\n",
    "data.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_columns = data.select_dtypes(include=['object']).columns\n",
    "label_encoders = {}\n",
    "for column in categorical_columns:\n",
    "    label_encoders[column] = LabelEncoder()\n",
    "    data[column] = label_encoders[column].fit_transform(data[column])\n",
    "\n",
    "# Print the value counts of the 'readmitted' column before transformation\n",
    "print(\"Value counts of the 'readmitted' column before transformation:\")\n",
    "print(data['readmitted'].value_counts())\n",
    "\n",
    "# Define the feature matrix and target vector\n",
    "X = data.drop(columns=['readmitted'])\n",
    "# Map readmitted column to binary values: 1 for '<30', 0 otherwise\n",
    "y = data['readmitted'].map(lambda x: 1 if x == 2 else 0)\n",
    "\n",
    "# Ensure that the target variable has both classes\n",
    "print(\"Value counts of the target variable (y):\")\n",
    "print(y.value_counts())\n",
    "\n",
    "# Check if the target variable has at least two classes\n",
    "if y.nunique() < 2:\n",
    "    raise ValueError(\"The target variable 'y' must have at least two classes. Please check the preprocessing steps.\")\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize the gradient boosting classifier\n",
    "gbc = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'max_depth': [3, 4, 5]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=gbc, param_grid=param_grid, cv=5, n_jobs=-1, scoring='roc_auc')\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Best model\n",
    "best_gbc = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = best_gbc.predict(X_test_scaled)\n",
    "y_pred_proba = best_gbc.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"ROC AUC Score:\")\n",
    "print(roc_auc_score(y_test, y_pred_proba))\n",
    "\n",
    "# Model performance\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "random_accuracy = np.mean(y_test)\n",
    "improvement_factor = accuracy / random_accuracy\n",
    "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Random Guessing Accuracy: {random_accuracy:.2f}\")\n",
    "print(f\"Improvement Factor: {improvement_factor:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba3c1fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 101766 entries, 0 to 101765\n",
      "Data columns (total 50 columns):\n",
      " #   Column                    Non-Null Count   Dtype \n",
      "---  ------                    --------------   ----- \n",
      " 0   encounter_id              101766 non-null  int64 \n",
      " 1   patient_nbr               101766 non-null  int64 \n",
      " 2   race                      101766 non-null  object\n",
      " 3   gender                    101766 non-null  object\n",
      " 4   age                       101766 non-null  object\n",
      " 5   weight                    101766 non-null  object\n",
      " 6   admission_type_id         101766 non-null  int64 \n",
      " 7   discharge_disposition_id  101766 non-null  int64 \n",
      " 8   admission_source_id       101766 non-null  int64 \n",
      " 9   time_in_hospital          101766 non-null  int64 \n",
      " 10  payer_code                101766 non-null  object\n",
      " 11  medical_specialty         101766 non-null  object\n",
      " 12  num_lab_procedures        101766 non-null  int64 \n",
      " 13  num_procedures            101766 non-null  int64 \n",
      " 14  num_medications           101766 non-null  int64 \n",
      " 15  number_outpatient         101766 non-null  int64 \n",
      " 16  number_emergency          101766 non-null  int64 \n",
      " 17  number_inpatient          101766 non-null  int64 \n",
      " 18  diag_1                    101766 non-null  object\n",
      " 19  diag_2                    101766 non-null  object\n",
      " 20  diag_3                    101766 non-null  object\n",
      " 21  number_diagnoses          101766 non-null  int64 \n",
      " 22  max_glu_serum             5346 non-null    object\n",
      " 23  A1Cresult                 17018 non-null   object\n",
      " 24  metformin                 101766 non-null  object\n",
      " 25  repaglinide               101766 non-null  object\n",
      " 26  nateglinide               101766 non-null  object\n",
      " 27  chlorpropamide            101766 non-null  object\n",
      " 28  glimepiride               101766 non-null  object\n",
      " 29  acetohexamide             101766 non-null  object\n",
      " 30  glipizide                 101766 non-null  object\n",
      " 31  glyburide                 101766 non-null  object\n",
      " 32  tolbutamide               101766 non-null  object\n",
      " 33  pioglitazone              101766 non-null  object\n",
      " 34  rosiglitazone             101766 non-null  object\n",
      " 35  acarbose                  101766 non-null  object\n",
      " 36  miglitol                  101766 non-null  object\n",
      " 37  troglitazone              101766 non-null  object\n",
      " 38  tolazamide                101766 non-null  object\n",
      " 39  examide                   101766 non-null  object\n",
      " 40  citoglipton               101766 non-null  object\n",
      " 41  insulin                   101766 non-null  object\n",
      " 42  glyburide-metformin       101766 non-null  object\n",
      " 43  glipizide-metformin       101766 non-null  object\n",
      " 44  glimepiride-pioglitazone  101766 non-null  object\n",
      " 45  metformin-rosiglitazone   101766 non-null  object\n",
      " 46  metformin-pioglitazone    101766 non-null  object\n",
      " 47  change                    101766 non-null  object\n",
      " 48  diabetesMed               101766 non-null  object\n",
      " 49  readmitted                101766 non-null  object\n",
      "dtypes: int64(13), object(37)\n",
      "memory usage: 38.8+ MB\n",
      "None\n",
      "       encounter_id   patient_nbr  admission_type_id  \\\n",
      "count  1.017660e+05  1.017660e+05      101766.000000   \n",
      "mean   1.652016e+08  5.433040e+07           2.024006   \n",
      "std    1.026403e+08  3.869636e+07           1.445403   \n",
      "min    1.252200e+04  1.350000e+02           1.000000   \n",
      "25%    8.496119e+07  2.341322e+07           1.000000   \n",
      "50%    1.523890e+08  4.550514e+07           1.000000   \n",
      "75%    2.302709e+08  8.754595e+07           3.000000   \n",
      "max    4.438672e+08  1.895026e+08           8.000000   \n",
      "\n",
      "       discharge_disposition_id  admission_source_id  time_in_hospital  \\\n",
      "count             101766.000000        101766.000000     101766.000000   \n",
      "mean                   3.715642             5.754437          4.395987   \n",
      "std                    5.280166             4.064081          2.985108   \n",
      "min                    1.000000             1.000000          1.000000   \n",
      "25%                    1.000000             1.000000          2.000000   \n",
      "50%                    1.000000             7.000000          4.000000   \n",
      "75%                    4.000000             7.000000          6.000000   \n",
      "max                   28.000000            25.000000         14.000000   \n",
      "\n",
      "       num_lab_procedures  num_procedures  num_medications  number_outpatient  \\\n",
      "count       101766.000000   101766.000000    101766.000000      101766.000000   \n",
      "mean            43.095641        1.339730        16.021844           0.369357   \n",
      "std             19.674362        1.705807         8.127566           1.267265   \n",
      "min              1.000000        0.000000         1.000000           0.000000   \n",
      "25%             31.000000        0.000000        10.000000           0.000000   \n",
      "50%             44.000000        1.000000        15.000000           0.000000   \n",
      "75%             57.000000        2.000000        20.000000           0.000000   \n",
      "max            132.000000        6.000000        81.000000          42.000000   \n",
      "\n",
      "       number_emergency  number_inpatient  number_diagnoses  \n",
      "count     101766.000000     101766.000000     101766.000000  \n",
      "mean           0.197836          0.635566          7.422607  \n",
      "std            0.930472          1.262863          1.933600  \n",
      "min            0.000000          0.000000          1.000000  \n",
      "25%            0.000000          0.000000          6.000000  \n",
      "50%            0.000000          0.000000          8.000000  \n",
      "75%            0.000000          1.000000          9.000000  \n",
      "max           76.000000         21.000000         16.000000  \n",
      "Value counts of the 'readmitted' column before transformation:\n",
      "readmitted\n",
      "2    54864\n",
      "1    35545\n",
      "0    11357\n",
      "Name: count, dtype: int64\n",
      "Value counts of the target variable (y):\n",
      "readmitted\n",
      "1    54864\n",
      "0    46902\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient Boosting Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.61      0.63      9381\n",
      "           1       0.68      0.73      0.70     10973\n",
      "\n",
      "    accuracy                           0.67     20354\n",
      "   macro avg       0.67      0.67      0.67     20354\n",
      "weighted avg       0.67      0.67      0.67     20354\n",
      "\n",
      "Gradient Boosting Confusion Matrix:\n",
      "[[5714 3667]\n",
      " [3012 7961]]\n",
      "Gradient Boosting ROC AUC Score:\n",
      "0.7340286450700532\n",
      "Gradient Boosting Model Accuracy: 0.67\n",
      "Gradient Boosting Random Guessing Accuracy: 0.54\n",
      "Gradient Boosting Improvement Factor: 1.25\n",
      "\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.44      0.53      9381\n",
      "           1       0.63      0.80      0.70     10973\n",
      "\n",
      "    accuracy                           0.64     20354\n",
      "   macro avg       0.64      0.62      0.62     20354\n",
      "weighted avg       0.64      0.64      0.62     20354\n",
      "\n",
      "Random Forest Confusion Matrix:\n",
      "[[4156 5225]\n",
      " [2177 8796]]\n",
      "Random Forest ROC AUC Score:\n",
      "0.6897886200366624\n",
      "Random Forest Model Accuracy: 0.64\n",
      "Random Forest Random Guessing Accuracy: 0.54\n",
      "Random Forest Improvement Factor: 1.18\n",
      "\n",
      "XGBoost Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.61      0.63      9381\n",
      "           1       0.69      0.73      0.71     10973\n",
      "\n",
      "    accuracy                           0.68     20354\n",
      "   macro avg       0.67      0.67      0.67     20354\n",
      "weighted avg       0.67      0.68      0.67     20354\n",
      "\n",
      "XGBoost Confusion Matrix:\n",
      "[[5748 3633]\n",
      " [2980 7993]]\n",
      "XGBoost ROC AUC Score:\n",
      "0.7359469021815164\n",
      "XGBoost Model Accuracy: 0.68\n",
      "XGBoost Random Guessing Accuracy: 0.54\n",
      "XGBoost Improvement Factor: 1.25\n",
      "\n",
      "Voting Classifier Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.58      0.62      9381\n",
      "           1       0.68      0.75      0.71     10973\n",
      "\n",
      "    accuracy                           0.67     20354\n",
      "   macro avg       0.67      0.66      0.66     20354\n",
      "weighted avg       0.67      0.67      0.67     20354\n",
      "\n",
      "Voting Classifier Confusion Matrix:\n",
      "[[5441 3940]\n",
      " [2762 8211]]\n",
      "Voting Classifier ROC AUC Score:\n",
      "0.7340567397295877\n",
      "Voting Classifier Model Accuracy: 0.67\n",
      "Voting Classifier Random Guessing Accuracy: 0.54\n",
      "Voting Classifier Improvement Factor: 1.24\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "import xgboost as xgb\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('diabetic_data.csv')\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(data.info())\n",
    "print(data.describe())\n",
    "\n",
    "# Data preprocessing\n",
    "# Remove columns with a single unique value\n",
    "data = data[[col for col in data.columns if data[col].nunique() > 1]]\n",
    "\n",
    "# Handle missing values\n",
    "data.replace('?', np.nan, inplace=True)\n",
    "data.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_columns = data.select_dtypes(include=['object']).columns\n",
    "label_encoders = {}\n",
    "for column in categorical_columns:\n",
    "    label_encoders[column] = LabelEncoder()\n",
    "    data[column] = label_encoders[column].fit_transform(data[column])\n",
    "\n",
    "# Print the value counts of the 'readmitted' column before transformation\n",
    "print(\"Value counts of the 'readmitted' column before transformation:\")\n",
    "print(data['readmitted'].value_counts())\n",
    "\n",
    "# Define the feature matrix and target vector\n",
    "X = data.drop(columns=['readmitted'])\n",
    "# Map readmitted column to binary values: 1 for '<30', 0 otherwise\n",
    "y = data['readmitted'].map(lambda x: 1 if x == 2 else 0)\n",
    "\n",
    "# Ensure that the target variable has both classes\n",
    "print(\"Value counts of the target variable (y):\")\n",
    "print(y.value_counts())\n",
    "\n",
    "# Check if the target variable has at least two classes\n",
    "if y.nunique() < 2:\n",
    "    raise ValueError(\"The target variable 'y' must have at least two classes. Please check the preprocessing steps.\")\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Gradient Boosting Classifier\n",
    "gbc = GradientBoostingClassifier(random_state=42)\n",
    "param_grid_gbc = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'max_depth': [3, 4, 5]\n",
    "}\n",
    "grid_search_gbc = GridSearchCV(estimator=gbc, param_grid=param_grid_gbc, cv=5, n_jobs=-1, scoring='roc_auc')\n",
    "grid_search_gbc.fit(X_train_scaled, y_train)\n",
    "best_gbc = grid_search_gbc.best_estimator_\n",
    "\n",
    "# Random Forest Classifier\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "grid_search_rf = GridSearchCV(estimator=rf_clf, param_grid=param_grid_rf, cv=5, n_jobs=-1, scoring='roc_auc')\n",
    "grid_search_rf.fit(X_train_scaled, y_train)\n",
    "best_rf = grid_search_rf.best_estimator_\n",
    "\n",
    "# XGBoost Classifier\n",
    "xgb_clf = xgb.XGBClassifier(random_state=42, eval_metric='logloss')\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "grid_search_xgb = GridSearchCV(estimator=xgb_clf, param_grid=param_grid_xgb, cv=5, n_jobs=-1, scoring='roc_auc')\n",
    "grid_search_xgb.fit(X_train_scaled, y_train)\n",
    "best_xgb = grid_search_xgb.best_estimator_\n",
    "\n",
    "# Ensemble Method: Voting Classifier\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('rf', best_rf),\n",
    "    ('gb', best_gbc),\n",
    "    ('xgb', best_xgb)\n",
    "], voting='soft')\n",
    "voting_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate all models\n",
    "models = {\n",
    "    \"Gradient Boosting\": best_gbc,\n",
    "    \"Random Forest\": best_rf,\n",
    "    \"XGBoost\": best_xgb,\n",
    "    \"Voting Classifier\": voting_clf\n",
    "}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    print(f\"\\n{model_name} Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"{model_name} Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(f\"{model_name} ROC AUC Score:\")\n",
    "    print(roc_auc_score(y_test, y_pred_proba))\n",
    "\n",
    "# Model performance\n",
    "    accuracy = np.mean(y_pred == y_test)\n",
    "    random_accuracy = np.mean(y_test)\n",
    "    improvement_factor = accuracy / random_accuracy\n",
    "    print(f\"{model_name} Model Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"{model_name} Random Guessing Accuracy: {random_accuracy:.2f}\")\n",
    "    print(f\"{model_name} Improvement Factor: {improvement_factor:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbf677dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 101766 entries, 0 to 101765\n",
      "Data columns (total 50 columns):\n",
      " #   Column                    Non-Null Count   Dtype \n",
      "---  ------                    --------------   ----- \n",
      " 0   encounter_id              101766 non-null  int64 \n",
      " 1   patient_nbr               101766 non-null  int64 \n",
      " 2   race                      101766 non-null  object\n",
      " 3   gender                    101766 non-null  object\n",
      " 4   age                       101766 non-null  object\n",
      " 5   weight                    101766 non-null  object\n",
      " 6   admission_type_id         101766 non-null  int64 \n",
      " 7   discharge_disposition_id  101766 non-null  int64 \n",
      " 8   admission_source_id       101766 non-null  int64 \n",
      " 9   time_in_hospital          101766 non-null  int64 \n",
      " 10  payer_code                101766 non-null  object\n",
      " 11  medical_specialty         101766 non-null  object\n",
      " 12  num_lab_procedures        101766 non-null  int64 \n",
      " 13  num_procedures            101766 non-null  int64 \n",
      " 14  num_medications           101766 non-null  int64 \n",
      " 15  number_outpatient         101766 non-null  int64 \n",
      " 16  number_emergency          101766 non-null  int64 \n",
      " 17  number_inpatient          101766 non-null  int64 \n",
      " 18  diag_1                    101766 non-null  object\n",
      " 19  diag_2                    101766 non-null  object\n",
      " 20  diag_3                    101766 non-null  object\n",
      " 21  number_diagnoses          101766 non-null  int64 \n",
      " 22  max_glu_serum             5346 non-null    object\n",
      " 23  A1Cresult                 17018 non-null   object\n",
      " 24  metformin                 101766 non-null  object\n",
      " 25  repaglinide               101766 non-null  object\n",
      " 26  nateglinide               101766 non-null  object\n",
      " 27  chlorpropamide            101766 non-null  object\n",
      " 28  glimepiride               101766 non-null  object\n",
      " 29  acetohexamide             101766 non-null  object\n",
      " 30  glipizide                 101766 non-null  object\n",
      " 31  glyburide                 101766 non-null  object\n",
      " 32  tolbutamide               101766 non-null  object\n",
      " 33  pioglitazone              101766 non-null  object\n",
      " 34  rosiglitazone             101766 non-null  object\n",
      " 35  acarbose                  101766 non-null  object\n",
      " 36  miglitol                  101766 non-null  object\n",
      " 37  troglitazone              101766 non-null  object\n",
      " 38  tolazamide                101766 non-null  object\n",
      " 39  examide                   101766 non-null  object\n",
      " 40  citoglipton               101766 non-null  object\n",
      " 41  insulin                   101766 non-null  object\n",
      " 42  glyburide-metformin       101766 non-null  object\n",
      " 43  glipizide-metformin       101766 non-null  object\n",
      " 44  glimepiride-pioglitazone  101766 non-null  object\n",
      " 45  metformin-rosiglitazone   101766 non-null  object\n",
      " 46  metformin-pioglitazone    101766 non-null  object\n",
      " 47  change                    101766 non-null  object\n",
      " 48  diabetesMed               101766 non-null  object\n",
      " 49  readmitted                101766 non-null  object\n",
      "dtypes: int64(13), object(37)\n",
      "memory usage: 38.8+ MB\n",
      "None\n",
      "       encounter_id   patient_nbr  admission_type_id  \\\n",
      "count  1.017660e+05  1.017660e+05      101766.000000   \n",
      "mean   1.652016e+08  5.433040e+07           2.024006   \n",
      "std    1.026403e+08  3.869636e+07           1.445403   \n",
      "min    1.252200e+04  1.350000e+02           1.000000   \n",
      "25%    8.496119e+07  2.341322e+07           1.000000   \n",
      "50%    1.523890e+08  4.550514e+07           1.000000   \n",
      "75%    2.302709e+08  8.754595e+07           3.000000   \n",
      "max    4.438672e+08  1.895026e+08           8.000000   \n",
      "\n",
      "       discharge_disposition_id  admission_source_id  time_in_hospital  \\\n",
      "count             101766.000000        101766.000000     101766.000000   \n",
      "mean                   3.715642             5.754437          4.395987   \n",
      "std                    5.280166             4.064081          2.985108   \n",
      "min                    1.000000             1.000000          1.000000   \n",
      "25%                    1.000000             1.000000          2.000000   \n",
      "50%                    1.000000             7.000000          4.000000   \n",
      "75%                    4.000000             7.000000          6.000000   \n",
      "max                   28.000000            25.000000         14.000000   \n",
      "\n",
      "       num_lab_procedures  num_procedures  num_medications  number_outpatient  \\\n",
      "count       101766.000000   101766.000000    101766.000000      101766.000000   \n",
      "mean            43.095641        1.339730        16.021844           0.369357   \n",
      "std             19.674362        1.705807         8.127566           1.267265   \n",
      "min              1.000000        0.000000         1.000000           0.000000   \n",
      "25%             31.000000        0.000000        10.000000           0.000000   \n",
      "50%             44.000000        1.000000        15.000000           0.000000   \n",
      "75%             57.000000        2.000000        20.000000           0.000000   \n",
      "max            132.000000        6.000000        81.000000          42.000000   \n",
      "\n",
      "       number_emergency  number_inpatient  number_diagnoses  \n",
      "count     101766.000000     101766.000000     101766.000000  \n",
      "mean           0.197836          0.635566          7.422607  \n",
      "std            0.930472          1.262863          1.933600  \n",
      "min            0.000000          0.000000          1.000000  \n",
      "25%            0.000000          0.000000          6.000000  \n",
      "50%            0.000000          0.000000          8.000000  \n",
      "75%            0.000000          1.000000          9.000000  \n",
      "max           76.000000         21.000000         16.000000  \n",
      "Value counts of the 'readmitted' column before transformation:\n",
      "readmitted\n",
      "2    54864\n",
      "1    35545\n",
      "0    11357\n",
      "Name: count, dtype: int64\n",
      "Value counts of the target variable (y):\n",
      "readmitted\n",
      "1    54864\n",
      "0    46902\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient Boosting Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.61      0.63      9381\n",
      "           1       0.68      0.73      0.70     10973\n",
      "\n",
      "    accuracy                           0.67     20354\n",
      "   macro avg       0.67      0.67      0.67     20354\n",
      "weighted avg       0.67      0.67      0.67     20354\n",
      "\n",
      "Gradient Boosting Confusion Matrix:\n",
      "[[5714 3667]\n",
      " [3012 7961]]\n",
      "Gradient Boosting ROC AUC Score:\n",
      "0.7340286450700532\n",
      "Gradient Boosting Model Accuracy: 0.67\n",
      "Gradient Boosting Random Guessing Accuracy: 0.54\n",
      "Gradient Boosting Improvement Factor: 1.25\n",
      "\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.44      0.53      9381\n",
      "           1       0.63      0.80      0.70     10973\n",
      "\n",
      "    accuracy                           0.64     20354\n",
      "   macro avg       0.64      0.62      0.62     20354\n",
      "weighted avg       0.64      0.64      0.62     20354\n",
      "\n",
      "Random Forest Confusion Matrix:\n",
      "[[4156 5225]\n",
      " [2177 8796]]\n",
      "Random Forest ROC AUC Score:\n",
      "0.6897886200366624\n",
      "Random Forest Model Accuracy: 0.64\n",
      "Random Forest Random Guessing Accuracy: 0.54\n",
      "Random Forest Improvement Factor: 1.18\n",
      "\n",
      "XGBoost Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.61      0.63      9381\n",
      "           1       0.69      0.73      0.71     10973\n",
      "\n",
      "    accuracy                           0.68     20354\n",
      "   macro avg       0.67      0.67      0.67     20354\n",
      "weighted avg       0.67      0.68      0.67     20354\n",
      "\n",
      "XGBoost Confusion Matrix:\n",
      "[[5748 3633]\n",
      " [2980 7993]]\n",
      "XGBoost ROC AUC Score:\n",
      "0.7359469021815164\n",
      "XGBoost Model Accuracy: 0.68\n",
      "XGBoost Random Guessing Accuracy: 0.54\n",
      "XGBoost Improvement Factor: 1.25\n",
      "\n",
      "Voting Classifier Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.58      0.62      9381\n",
      "           1       0.68      0.75      0.71     10973\n",
      "\n",
      "    accuracy                           0.67     20354\n",
      "   macro avg       0.67      0.66      0.66     20354\n",
      "weighted avg       0.67      0.67      0.67     20354\n",
      "\n",
      "Voting Classifier Confusion Matrix:\n",
      "[[5441 3940]\n",
      " [2762 8211]]\n",
      "Voting Classifier ROC AUC Score:\n",
      "0.7340567397295877\n",
      "Voting Classifier Model Accuracy: 0.67\n",
      "Voting Classifier Random Guessing Accuracy: 0.54\n",
      "Voting Classifier Improvement Factor: 1.24\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "import xgboost as xgb\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('diabetic_data.csv')\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(data.info())\n",
    "print(data.describe())\n",
    "\n",
    "# Data preprocessing\n",
    "# Remove columns with a single unique value\n",
    "data = data[[col for col in data.columns if data[col].nunique() > 1]]\n",
    "\n",
    "# Handle missing values\n",
    "data.replace('?', np.nan, inplace=True)\n",
    "data.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_columns = data.select_dtypes(include=['object']).columns\n",
    "label_encoders = {}\n",
    "for column in categorical_columns:\n",
    "    label_encoders[column] = LabelEncoder()\n",
    "    data[column] = label_encoders[column].fit_transform(data[column])\n",
    "\n",
    "# Print the value counts of the 'readmitted' column before transformation\n",
    "print(\"Value counts of the 'readmitted' column before transformation:\")\n",
    "print(data['readmitted'].value_counts())\n",
    "\n",
    "# Define the feature matrix and target vector\n",
    "X = data.drop(columns=['readmitted'])\n",
    "# Map readmitted column to binary values: 1 for '<30', 0 otherwise\n",
    "y = data['readmitted'].map(lambda x: 1 if x == 2 else 0)\n",
    "\n",
    "# Ensure that the target variable has both classes\n",
    "print(\"Value counts of the target variable (y):\")\n",
    "print(y.value_counts())\n",
    "\n",
    "# Check if the target variable has at least two classes\n",
    "if y.nunique() < 2:\n",
    "    raise ValueError(\"The target variable 'y' must have at least two classes. Please check the preprocessing steps.\")\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Gradient Boosting Classifier\n",
    "gbc = GradientBoostingClassifier(random_state=42)\n",
    "param_grid_gbc = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'max_depth': [3, 4, 5]\n",
    "}\n",
    "grid_search_gbc = GridSearchCV(estimator=gbc, param_grid=param_grid_gbc, cv=5, n_jobs=2, scoring='roc_auc')\n",
    "grid_search_gbc.fit(X_train_scaled, y_train)\n",
    "best_gbc = grid_search_gbc.best_estimator_\n",
    "\n",
    "# Random Forest Classifier\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "grid_search_rf = GridSearchCV(estimator=rf_clf, param_grid=param_grid_rf, cv=5, n_jobs=2, scoring='roc_auc')\n",
    "grid_search_rf.fit(X_train_scaled, y_train)\n",
    "best_rf = grid_search_rf.best_estimator_\n",
    "\n",
    "# XGBoost Classifier\n",
    "xgb_clf = xgb.XGBClassifier(random_state=42, eval_metric='logloss')\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "grid_search_xgb = GridSearchCV(estimator=xgb_clf, param_grid=param_grid_xgb, cv=5, n_jobs=2, scoring='roc_auc')\n",
    "grid_search_xgb.fit(X_train_scaled, y_train)\n",
    "best_xgb = grid_search_xgb.best_estimator_\n",
    "\n",
    "# Ensemble Method: Voting Classifier\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('rf', best_rf),\n",
    "    ('gb', best_gbc),\n",
    "    ('xgb', best_xgb)\n",
    "], voting='soft')\n",
    "voting_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate all models\n",
    "models = {\n",
    "    \"Gradient Boosting\": best_gbc,\n",
    "    \"Random Forest\": best_rf,\n",
    "    \"XGBoost\": best_xgb,\n",
    "    \"Voting Classifier\": voting_clf\n",
    "}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    print(f\"\\n{model_name} Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"{model_name} Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(f\"{model_name} ROC AUC Score:\")\n",
    "    print(roc_auc_score(y_test, y_pred_proba))\n",
    "\n",
    "    # Model performance\n",
    "    accuracy = np.mean(y_pred == y_test)\n",
    "    random_accuracy = np.mean(y_test)\n",
    "    improvement_factor = accuracy / random_accuracy\n",
    "    print(f\"{model_name} Model Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"{model_name} Random Guessing Accuracy: {random_accuracy:.2f}\")\n",
    "    print(f\"{model_name} Improvement Factor: {improvement_factor:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82f7ee89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 101766 entries, 0 to 101765\n",
      "Data columns (total 50 columns):\n",
      " #   Column                    Non-Null Count   Dtype \n",
      "---  ------                    --------------   ----- \n",
      " 0   encounter_id              101766 non-null  int64 \n",
      " 1   patient_nbr               101766 non-null  int64 \n",
      " 2   race                      101766 non-null  object\n",
      " 3   gender                    101766 non-null  object\n",
      " 4   age                       101766 non-null  object\n",
      " 5   weight                    101766 non-null  object\n",
      " 6   admission_type_id         101766 non-null  int64 \n",
      " 7   discharge_disposition_id  101766 non-null  int64 \n",
      " 8   admission_source_id       101766 non-null  int64 \n",
      " 9   time_in_hospital          101766 non-null  int64 \n",
      " 10  payer_code                101766 non-null  object\n",
      " 11  medical_specialty         101766 non-null  object\n",
      " 12  num_lab_procedures        101766 non-null  int64 \n",
      " 13  num_procedures            101766 non-null  int64 \n",
      " 14  num_medications           101766 non-null  int64 \n",
      " 15  number_outpatient         101766 non-null  int64 \n",
      " 16  number_emergency          101766 non-null  int64 \n",
      " 17  number_inpatient          101766 non-null  int64 \n",
      " 18  diag_1                    101766 non-null  object\n",
      " 19  diag_2                    101766 non-null  object\n",
      " 20  diag_3                    101766 non-null  object\n",
      " 21  number_diagnoses          101766 non-null  int64 \n",
      " 22  max_glu_serum             5346 non-null    object\n",
      " 23  A1Cresult                 17018 non-null   object\n",
      " 24  metformin                 101766 non-null  object\n",
      " 25  repaglinide               101766 non-null  object\n",
      " 26  nateglinide               101766 non-null  object\n",
      " 27  chlorpropamide            101766 non-null  object\n",
      " 28  glimepiride               101766 non-null  object\n",
      " 29  acetohexamide             101766 non-null  object\n",
      " 30  glipizide                 101766 non-null  object\n",
      " 31  glyburide                 101766 non-null  object\n",
      " 32  tolbutamide               101766 non-null  object\n",
      " 33  pioglitazone              101766 non-null  object\n",
      " 34  rosiglitazone             101766 non-null  object\n",
      " 35  acarbose                  101766 non-null  object\n",
      " 36  miglitol                  101766 non-null  object\n",
      " 37  troglitazone              101766 non-null  object\n",
      " 38  tolazamide                101766 non-null  object\n",
      " 39  examide                   101766 non-null  object\n",
      " 40  citoglipton               101766 non-null  object\n",
      " 41  insulin                   101766 non-null  object\n",
      " 42  glyburide-metformin       101766 non-null  object\n",
      " 43  glipizide-metformin       101766 non-null  object\n",
      " 44  glimepiride-pioglitazone  101766 non-null  object\n",
      " 45  metformin-rosiglitazone   101766 non-null  object\n",
      " 46  metformin-pioglitazone    101766 non-null  object\n",
      " 47  change                    101766 non-null  object\n",
      " 48  diabetesMed               101766 non-null  object\n",
      " 49  readmitted                101766 non-null  object\n",
      "dtypes: int64(13), object(37)\n",
      "memory usage: 38.8+ MB\n",
      "None\n",
      "       encounter_id   patient_nbr  admission_type_id  \\\n",
      "count  1.017660e+05  1.017660e+05      101766.000000   \n",
      "mean   1.652016e+08  5.433040e+07           2.024006   \n",
      "std    1.026403e+08  3.869636e+07           1.445403   \n",
      "min    1.252200e+04  1.350000e+02           1.000000   \n",
      "25%    8.496119e+07  2.341322e+07           1.000000   \n",
      "50%    1.523890e+08  4.550514e+07           1.000000   \n",
      "75%    2.302709e+08  8.754595e+07           3.000000   \n",
      "max    4.438672e+08  1.895026e+08           8.000000   \n",
      "\n",
      "       discharge_disposition_id  admission_source_id  time_in_hospital  \\\n",
      "count             101766.000000        101766.000000     101766.000000   \n",
      "mean                   3.715642             5.754437          4.395987   \n",
      "std                    5.280166             4.064081          2.985108   \n",
      "min                    1.000000             1.000000          1.000000   \n",
      "25%                    1.000000             1.000000          2.000000   \n",
      "50%                    1.000000             7.000000          4.000000   \n",
      "75%                    4.000000             7.000000          6.000000   \n",
      "max                   28.000000            25.000000         14.000000   \n",
      "\n",
      "       num_lab_procedures  num_procedures  num_medications  number_outpatient  \\\n",
      "count       101766.000000   101766.000000    101766.000000      101766.000000   \n",
      "mean            43.095641        1.339730        16.021844           0.369357   \n",
      "std             19.674362        1.705807         8.127566           1.267265   \n",
      "min              1.000000        0.000000         1.000000           0.000000   \n",
      "25%             31.000000        0.000000        10.000000           0.000000   \n",
      "50%             44.000000        1.000000        15.000000           0.000000   \n",
      "75%             57.000000        2.000000        20.000000           0.000000   \n",
      "max            132.000000        6.000000        81.000000          42.000000   \n",
      "\n",
      "       number_emergency  number_inpatient  number_diagnoses  \n",
      "count     101766.000000     101766.000000     101766.000000  \n",
      "mean           0.197836          0.635566          7.422607  \n",
      "std            0.930472          1.262863          1.933600  \n",
      "min            0.000000          0.000000          1.000000  \n",
      "25%            0.000000          0.000000          6.000000  \n",
      "50%            0.000000          0.000000          8.000000  \n",
      "75%            0.000000          1.000000          9.000000  \n",
      "max           76.000000         21.000000         16.000000  \n",
      "Value counts of the 'readmitted' column before transformation:\n",
      "readmitted\n",
      "2    54864\n",
      "1    35545\n",
      "0    11357\n",
      "Name: count, dtype: int64\n",
      "Value counts of the target variable (y):\n",
      "readmitted\n",
      "1    54864\n",
      "0    46902\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 92\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name, model_info \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     91\u001b[0m     grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mmodel_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m], param_grid\u001b[38;5;241m=\u001b[39mmodel_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparam_grid\u001b[39m\u001b[38;5;124m'\u001b[39m], cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroc_auc\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 92\u001b[0m     grid_search\u001b[38;5;241m.\u001b[39mfit(X_train_scaled, y_train)\n\u001b[1;32m     93\u001b[0m     best_estimators[model_name] \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrid_search\u001b[38;5;241m.\u001b[39mbest_params_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    966\u001b[0m     )\n\u001b[1;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 970\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[1;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1527\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1527\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    913\u001b[0m         )\n\u001b[1;32m    914\u001b[0m     )\n\u001b[0;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    917\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    918\u001b[0m         clone(base_estimator),\n\u001b[1;32m    919\u001b[0m         X,\n\u001b[1;32m    920\u001b[0m         y,\n\u001b[1;32m    921\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[1;32m    922\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[1;32m    923\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[1;32m    924\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[1;32m    925\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[1;32m    926\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[1;32m    927\u001b[0m     )\n\u001b[1;32m    928\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[1;32m    929\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[1;32m    930\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[1;32m    931\u001b[0m     )\n\u001b[1;32m    932\u001b[0m )\n\u001b[1;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    939\u001b[0m     )\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretrieve()\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout))\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m future\u001b[38;5;241m.\u001b[39mresult(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.11/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.11/threading.py:327\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 327\u001b[0m         waiter\u001b[38;5;241m.\u001b[39macquire()\n\u001b[1;32m    328\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "import xgboost as xgb\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('diabetic_data.csv')\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(data.info())\n",
    "print(data.describe())\n",
    "\n",
    "# Data preprocessing\n",
    "# Remove columns with a single unique value\n",
    "data = data[[col for col in data.columns if data[col].nunique() > 1]]\n",
    "\n",
    "# Handle missing values\n",
    "data.replace('?', np.nan, inplace=True)\n",
    "data.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_columns = data.select_dtypes(include=['object']).columns\n",
    "label_encoders = {}\n",
    "for column in categorical_columns:\n",
    "    label_encoders[column] = LabelEncoder()\n",
    "    data[column] = label_encoders[column].fit_transform(data[column])\n",
    "\n",
    "# Print the value counts of the 'readmitted' column before transformation\n",
    "print(\"Value counts of the 'readmitted' column before transformation:\")\n",
    "print(data['readmitted'].value_counts())\n",
    "\n",
    "# Define the feature matrix and target vector\n",
    "X = data.drop(columns=['readmitted'])\n",
    "# Map readmitted column to binary values: 1 for '<30', 0 otherwise\n",
    "y = data['readmitted'].map(lambda x: 1 if x == 2 else 0)\n",
    "\n",
    "# Ensure that the target variable has both classes\n",
    "print(\"Value counts of the target variable (y):\")\n",
    "print(y.value_counts())\n",
    "\n",
    "# Check if the target variable has at least two classes\n",
    "if y.nunique() < 2:\n",
    "    raise ValueError(\"The target variable 'y' must have at least two classes. Please check the preprocessing steps.\")\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the models and their hyperparameters for GridSearchCV\n",
    "models = {\n",
    "    'Gradient Boosting': {\n",
    "        'model': GradientBoostingClassifier(random_state=42),\n",
    "        'param_grid': {\n",
    "            'n_estimators': [100, 200, 300],\n",
    "            'learning_rate': [0.01, 0.1, 0.05],\n",
    "            'max_depth': [3, 4, 5]\n",
    "        }\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'model': RandomForestClassifier(random_state=42),\n",
    "        'param_grid': {\n",
    "            'n_estimators': [100, 200, 300],\n",
    "            'max_depth': [3, 4, 5],\n",
    "            'min_samples_split': [2, 5, 10]\n",
    "        }\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'model': xgb.XGBClassifier(random_state=42, eval_metric='logloss'),\n",
    "        'param_grid': {\n",
    "            'n_estimators': [100, 200, 300],\n",
    "            'learning_rate': [0.01, 0.1, 0.05],\n",
    "            'max_depth': [3, 4, 5],\n",
    "            'subsample': [0.8, 1.0],\n",
    "            'colsample_bytree': [0.8, 1.0]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV and select the best model for each algorithm\n",
    "best_estimators = {}\n",
    "for model_name, model_info in models.items():\n",
    "    grid_search = GridSearchCV(estimator=model_info['model'], param_grid=model_info['param_grid'], cv=5, n_jobs=2, scoring='roc_auc')\n",
    "    grid_search.fit(X_train_scaled, y_train)\n",
    "    best_estimators[model_name] = grid_search.best_estimator_\n",
    "    print(f\"Best parameters for {model_name}: {grid_search.best_params_}\")\n",
    "\n",
    "# Ensemble Method: Voting Classifier\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('rf', best_estimators['Random Forest']),\n",
    "    ('gb', best_estimators['Gradient Boosting']),\n",
    "    ('xgb', best_estimators['XGBoost'])\n",
    "], voting='soft')\n",
    "voting_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate all models using cross-validation\n",
    "for model_name, model in best_estimators.items():\n",
    "    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='roc_auc')\n",
    "    print(f\"{model_name} Cross-Validation ROC AUC Score: {cv_scores.mean()}\")\n",
    "\n",
    "# Evaluate all models on the test set\n",
    "models['Voting Classifier'] = {'model': voting_clf}\n",
    "for model_name, model_info in models.items():\n",
    "    model = model_info['model']\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    print(f\"\\n{model_name} Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"{model_name} Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(f\"{model_name} ROC AUC Score:\")\n",
    "    print(roc_auc_score(y_test, y_pred_proba))\n",
    "\n",
    "    # Model performance\n",
    "    accuracy = np.mean(y_pred == y_test)\n",
    "    random_accuracy = np.mean(y_test)\n",
    "    improvement_factor = accuracy / random_accuracy\n",
    "    print(f\"{model_name} Model Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"{model_name} Random Guessing Accuracy: {random_accuracy:.2f}\")\n",
    "    print(f\"{model_name} Improvement Factor: {improvement_factor:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684fd692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-numeric columns: Index(['diag_1', 'diag_2', 'diag_3', 'metformin', 'repaglinide', 'nateglinide',\n",
      "       'chlorpropamide', 'glimepiride', 'acetohexamide', 'glipizide',\n",
      "       'glyburide', 'tolbutamide', 'pioglitazone', 'rosiglitazone', 'acarbose',\n",
      "       'miglitol', 'troglitazone', 'tolazamide', 'examide', 'citoglipton',\n",
      "       'insulin', 'glyburide-metformin', 'glipizide-metformin',\n",
      "       'glimepiride-pioglitazone', 'metformin-rosiglitazone',\n",
      "       'metformin-pioglitazone', 'num_medications_age'],\n",
      "      dtype='object')\n",
      "Columns after encoding: Index([], dtype='object')\n",
      "Selected features: Index(['time_in_hospital', 'num_lab_procedures', 'num_procedures',\n",
      "       'num_medications', 'number_outpatient', 'number_emergency',\n",
      "       'number_inpatient', 'diag_1', 'diag_2', 'diag_3', 'number_diagnoses',\n",
      "       'metformin', 'repaglinide', 'nateglinide', 'chlorpropamide',\n",
      "       'glimepiride', 'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide',\n",
      "       'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone',\n",
      "       'tolazamide', 'insulin', 'glyburide-metformin', 'glipizide-metformin',\n",
      "       'glimepiride-pioglitazone', 'metformin-pioglitazone',\n",
      "       'num_medications_age', 'num_lab_procedures_num_medications',\n",
      "       'race_Caucasian', 'race_Hispanic', 'race_Other', 'gender_Male',\n",
      "       'gender_Unknown/Invalid', 'age_[10-20)', 'age_[20-30)', 'age_[30-40)',\n",
      "       'age_[40-50)', 'age_[50-60)', 'age_[60-70)', 'age_[80-90)',\n",
      "       'age_[90-100)', 'admission_type_id_2', 'admission_type_id_3',\n",
      "       'admission_type_id_4', 'admission_type_id_5', 'admission_type_id_6',\n",
      "       'admission_type_id_7', 'admission_type_id_8',\n",
      "       'discharge_disposition_id_2', 'discharge_disposition_id_3',\n",
      "       'discharge_disposition_id_4', 'discharge_disposition_id_5',\n",
      "       'discharge_disposition_id_6', 'discharge_disposition_id_7',\n",
      "       'discharge_disposition_id_8', 'discharge_disposition_id_9',\n",
      "       'discharge_disposition_id_10', 'discharge_disposition_id_11',\n",
      "       'discharge_disposition_id_12', 'discharge_disposition_id_13',\n",
      "       'discharge_disposition_id_14', 'discharge_disposition_id_15',\n",
      "       'discharge_disposition_id_16', 'discharge_disposition_id_17',\n",
      "       'discharge_disposition_id_18', 'discharge_disposition_id_19',\n",
      "       'discharge_disposition_id_20', 'discharge_disposition_id_22',\n",
      "       'discharge_disposition_id_23', 'discharge_disposition_id_24',\n",
      "       'discharge_disposition_id_25', 'discharge_disposition_id_27',\n",
      "       'discharge_disposition_id_28', 'admission_source_id_2',\n",
      "       'admission_source_id_3', 'admission_source_id_4',\n",
      "       'admission_source_id_5', 'admission_source_id_6',\n",
      "       'admission_source_id_7', 'admission_source_id_8',\n",
      "       'admission_source_id_9', 'admission_source_id_10',\n",
      "       'admission_source_id_11', 'admission_source_id_14',\n",
      "       'admission_source_id_17', 'admission_source_id_20',\n",
      "       'admission_source_id_22', 'admission_source_id_25',\n",
      "       'max_glu_serum_>300', 'max_glu_serum_Norm', 'A1Cresult_>8',\n",
      "       'A1Cresult_Norm', 'change_No', 'diabetesMed_Yes'],\n",
      "      dtype='object')\n",
      "Decision Tree:\n",
      "Accuracy: 0.7951153324287653\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.87      0.88     17724\n",
      "           1       0.15      0.18      0.16      2175\n",
      "\n",
      "    accuracy                           0.80     19899\n",
      "   macro avg       0.52      0.53      0.52     19899\n",
      "weighted avg       0.81      0.80      0.80     19899\n",
      "\n",
      "ROC-AUC: 0.5251987564105558\n",
      "Logistic Regression:\n",
      "Accuracy: 0.6482737826021409\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.66      0.77     17724\n",
      "           1       0.16      0.54      0.25      2175\n",
      "\n",
      "    accuracy                           0.65     19899\n",
      "   macro avg       0.54      0.60      0.51     19899\n",
      "weighted avg       0.84      0.65      0.71     19899\n",
      "\n",
      "ROC-AUC: 0.5990660627709165\n",
      "Gradient Boosting:\n",
      "Accuracy: 0.8863761998090356\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94     17724\n",
      "           1       0.31      0.03      0.06      2175\n",
      "\n",
      "    accuracy                           0.89     19899\n",
      "   macro avg       0.60      0.51      0.50     19899\n",
      "weighted avg       0.83      0.89      0.84     19899\n",
      "\n",
      "ROC-AUC: 0.5112877921228959\n",
      "XGBoost:\n",
      "Accuracy: 0.8902457409920097\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94     17724\n",
      "           1       0.47      0.04      0.07      2175\n",
      "\n",
      "    accuracy                           0.89     19899\n",
      "   macro avg       0.68      0.52      0.51     19899\n",
      "weighted avg       0.85      0.89      0.85     19899\n",
      "\n",
      "ROC-AUC: 0.5160817593911237\n"
     ]
    }
   ],
   "source": [
    "# Data Preprocessing and Model Building in One Cell\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression, LassoCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, confusion_matrix\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('diabetic_data.csv')\n",
    "data.replace('?', np.nan, inplace=True)\n",
    "data.drop(columns=['weight', 'payer_code', 'medical_specialty'], inplace=True)\n",
    "data.dropna(subset=['race', 'gender', 'age'], inplace=True)\n",
    "\n",
    "# Feature Engineering\n",
    "data['num_medications_age'] = data['num_medications'] * data['age']\n",
    "data['num_lab_procedures_num_medications'] = data['num_lab_procedures'] * data['num_medications']\n",
    "\n",
    "# Encode categorical variables\n",
    "categorical_columns = ['race', 'gender', 'age', 'admission_type_id', 'discharge_disposition_id', 'admission_source_id',\n",
    "                       'max_glu_serum', 'A1Cresult', 'change', 'diabetesMed']\n",
    "data = pd.get_dummies(data, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "# Encode the target variable\n",
    "data['readmitted'] = data['readmitted'].apply(lambda x: 1 if x == '<30' else 0)\n",
    "\n",
    "# Define features and target variable\n",
    "X = data.drop(columns=['readmitted', 'encounter_id', 'patient_nbr'])\n",
    "y = data['readmitted']\n",
    "\n",
    "# Ensure all columns are numeric\n",
    "non_numeric_columns = X.select_dtypes(include=['object']).columns\n",
    "print(\"Non-numeric columns:\", non_numeric_columns)\n",
    "\n",
    "# Encode any remaining non-numeric columns\n",
    "for col in non_numeric_columns:\n",
    "    X[col] = pd.Categorical(X[col]).codes\n",
    "\n",
    "# Ensure there are no non-numeric columns left\n",
    "print(\"Columns after encoding:\", X.select_dtypes(include=['object']).columns)\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Lasso for variable selection\n",
    "lasso = LassoCV(cv=5, n_jobs=-1).fit(X_train_smote, y_train_smote)\n",
    "importance = np.abs(lasso.coef_)\n",
    "selected_features = X.columns[importance > 0]\n",
    "print(\"Selected features:\", selected_features)\n",
    "\n",
    "# Use selected features\n",
    "X_train_selected = X_train_smote[:, importance > 0]\n",
    "X_valid_selected = X_valid_scaled[:, importance > 0]\n",
    "\n",
    "# Decision Tree\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train_selected, y_train_smote)\n",
    "y_pred_dt = dt.predict(X_valid_selected)\n",
    "print(\"Decision Tree:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_valid, y_pred_dt))\n",
    "print(\"Classification Report:\\n\", classification_report(y_valid, y_pred_dt))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_valid, y_pred_dt))\n",
    "\n",
    "# Logistic Regression\n",
    "log_reg = LogisticRegression(solver='lbfgs', max_iter=500, n_jobs=-1)\n",
    "log_reg.fit(X_train_selected, y_train_smote)\n",
    "y_pred_log_reg = log_reg.predict(X_valid_selected)\n",
    "print(\"Logistic Regression:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_valid, y_pred_log_reg))\n",
    "print(\"Classification Report:\\n\", classification_report(y_valid, y_pred_log_reg))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_valid, y_pred_log_reg))\n",
    "\n",
    "# Gradient Boosting\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "gb.fit(X_train_selected, y_train_smote)\n",
    "y_pred_gb = gb.predict(X_valid_selected)\n",
    "print(\"Gradient Boosting:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_valid, y_pred_gb))\n",
    "print(\"Classification Report:\\n\", classification_report(y_valid, y_pred_gb))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_valid, y_pred_gb))\n",
    "\n",
    "# XGBoost\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42, n_jobs=-1)\n",
    "xgb_model.fit(X_train_selected, y_train_smote)\n",
    "y_pred_xgb = xgb_model.predict(X_valid_selected)\n",
    "print(\"XGBoost:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_valid, y_pred_xgb))\n",
    "print(\"Classification Report:\\n\", classification_report(y_valid, y_pred_xgb))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_valid, y_pred_xgb))\n",
    "\n",
    "# Support Vector Machine\n",
    "svm = SVC(kernel='linear', probability=True, random_state=42)\n",
    "svm.fit(X_train_selected, y_train_smote)\n",
    "y_pred_svm = svm.predict(X_valid_selected)\n",
    "print(\"Support Vector Machine:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_valid, y_pred_svm))\n",
    "print(\"Classification Report:\\n\", classification_report(y_valid, y_pred_svm))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_valid, y_pred_svm))\n",
    "\n",
    "# Model comparison\n",
    "models = ['Decision Tree', 'Logistic Regression', 'Gradient Boosting', 'XGBoost', 'SVM']\n",
    "accuracies = [accuracy_score(y_valid, y_pred_dt), accuracy_score(y_valid, y_pred_log_reg), accuracy_score(y_valid, y_pred_gb), accuracy_score(y_valid, y_pred_xgb), accuracy_score(y_valid, y_pred_svm)]\n",
    "roc_aucs = [roc_auc_score(y_valid, y_pred_dt), roc_auc_score(y_valid, y_pred_log_reg), roc_auc_score(y_valid, y_pred_gb), roc_auc_score(y_valid, y_pred_xgb), roc_auc_score(y_valid, y_pred_svm)]\n",
    "\n",
    "model_comparison = pd.DataFrame({\n",
    "    'Model': models,\n",
    "    'Accuracy': accuracies,\n",
    "    'ROC-AUC': roc_aucs\n",
    "})\n",
    "\n",
    "print(model_comparison)\n",
    "\n",
    "# Hyperparameter tuning for SVM\n",
    "param_grid_svm = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "grid_svm = GridSearchCV(SVC(probability=True, random_state=42), param_grid_svm, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "grid_svm.fit(X_train_selected, y_train_smote)\n",
    "\n",
    "# Best parameters and score for SVM\n",
    "print(\"Best parameters for SVM:\", grid_svm.best_params_)\n",
    "print(\"Best ROC-AUC score for SVM:\", grid_svm.best_score_)\n",
    "\n",
    "# Evaluate on the test set\n",
    "best_svm = grid_svm.best_estimator_\n",
    "y_pred_svm_best = best_svm.predict(X_valid_selected)\n",
    "\n",
    "print(\"SVM with Best Parameters:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_valid, y_pred_svm_best))\n",
    "print(\"Classification Report:\\n\", classification_report(y_valid, y_pred_svm_best))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_valid, y_pred_svm_best))\n",
    "\n",
    "conf_matrix_svm_best = confusion_matrix(y_valid, y_pred_svm_best)\n",
    "sns.heatmap(conf_matrix_svm_best, annot=True, fmt='d')\n",
    "plt.title(\"SVM with Best Parameters Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683a9825",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, LassoCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "data = pd.read_csv('diabetic_data.csv')\n",
    "data.replace('?', np.nan, inplace=True)\n",
    "data.drop(columns=['weight', 'payer_code', 'medical_specialty'], inplace=True)\n",
    "data.dropna(subset=['race', 'gender', 'age'], inplace=True)\n",
    "\n",
    "# Feature Engineering\n",
    "data['num_medications_age'] = data['num_medications'] * data['age']\n",
    "data['num_lab_procedures_num_medications'] = data['num_lab_procedures'] * data['num_medications']\n",
    "\n",
    "# Encode categorical variables\n",
    "categorical_columns = ['race', 'gender', 'age', 'admission_type_id', 'discharge_disposition_id', 'admission_source_id', 'max_glu_serum', 'A1Cresult', 'change', 'diabetesMed']\n",
    "data = pd.get_dummies(data, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "# Encode the target variable\n",
    "data['readmitted'] = data['readmitted'].apply(lambda x: 1 if x == '<30' else 0)\n",
    "\n",
    "# Define features and target variable\n",
    "X = data.drop(columns=['readmitted', 'encounter_id', 'patient_nbr'])\n",
    "y = data['readmitted']\n",
    "\n",
    "# Encode any remaining non-numeric columns\n",
    "non_numeric_columns = X.select_dtypes(include=['object']).columns\n",
    "for col in non_numeric_columns:\n",
    "    X[col] = pd.Categorical(X[col]).codes\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Feature selection with Lasso\n",
    "lasso = LassoCV(cv=5, n_jobs=-1).fit(X_train_smote, y_train_smote)\n",
    "importance = np.abs(lasso.coef_)\n",
    "selected_features = X.columns[importance > 0]\n",
    "\n",
    "# Use selected features\n",
    "X_train_selected = X_train_smote[:, importance > 0]\n",
    "X_valid_selected = X_valid_scaled[:, importance > 0]\n",
    "\n",
    "# Model evaluation function\n",
    "def evaluate_model(model, X_valid, y_valid):\n",
    "    y_pred = model.predict(X_valid)\n",
    "    accuracy = accuracy_score(y_valid, y_pred)\n",
    "    roc_auc = roc_auc_score(y_valid, y_pred)\n",
    "    precision = precision_score(y_valid, y_pred)\n",
    "    recall = recall_score(y_valid, y_pred)\n",
    "    f1 = f1_score(y_valid, y_pred)\n",
    "    return accuracy, roc_auc, precision, recall, f1\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    #'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    #'Logistic Regression': LogisticRegression(solver='lbfgs', max_iter=500, n_jobs=-1),\n",
    "    #'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    #'XGBoost': xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42, n_jobs=-1),\n",
    "    'SVM': SVC(kernel='linear', probability=True, random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "results = []\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train_selected, y_train_smote)\n",
    "    accuracy, roc_auc, precision, recall, f1 = evaluate_model(model, X_valid_selected, y_valid)\n",
    "    results.append([model_name, accuracy, roc_auc, precision, recall, f1])\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame(results, columns=['Model', 'Accuracy', 'ROC-AUC', 'Precision', 'Recall', 'F1'])\n",
    "print(results_df)\n",
    "\n",
    "# Hyperparameter tuning for SVM\n",
    "param_grid_svm = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "grid_svm = GridSearchCV(SVC(probability=True, random_state=42), param_grid_svm, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "grid_svm.fit(X_train_selected, y_train_smote)\n",
    "\n",
    "# Best parameters and score for SVM\n",
    "print(\"Best parameters for SVM:\", grid_svm.best_params_)\n",
    "print(\"Best ROC-AUC score for SVM:\", grid_svm.best_score_)\n",
    "\n",
    "# Evaluate on the validation set\n",
    "best_svm = grid_svm.best_estimator_\n",
    "accuracy, roc_auc, precision, recall, f1 = evaluate_model(best_svm, X_valid_selected, y_valid)\n",
    "\n",
    "print(\"SVM with Best Parameters:\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"ROC-AUC: {roc_auc}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1: {f1}\")\n",
    "\n",
    "conf_matrix_svm_best = confusion_matrix(y_valid, best_svm.predict(X_valid_selected))\n",
    "sns.heatmap(conf_matrix_svm_best, annot=True, fmt='d')\n",
    "plt.title(\"SVM with Best Parameters Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f281c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92a9faa5-e3af-44db-96b6-49eede68241f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cudf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcudf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcupy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cudf'"
     ]
    }
   ],
   "source": [
    "import cudf\n",
    "import cupy as cp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from cuml.preprocessing.model_selection import train_test_split\n",
    "from cuml.linear_model import LogisticRegression\n",
    "from cuml.ensemble import RandomForestClassifier\n",
    "from cuml.svm import SVC\n",
    "from cuml.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load and preprocess the dataset using cuDF\n",
    "data = cudf.read_csv('diabetic_data.csv')\n",
    "data = data.replace('?', np.nan)\n",
    "data = data.drop(columns=['weight', 'payer_code', 'medical_specialty'])\n",
    "data = data.dropna(subset=['race', 'gender', 'age'])\n",
    "\n",
    "# Feature Engineering\n",
    "data['num_medications_age'] = data['num_medications'] * data['age']\n",
    "data['num_lab_procedures_num_medications'] = data['num_lab_procedures'] * data['num_medications']\n",
    "\n",
    "# Encode categorical variables using cuDF\n",
    "categorical_columns = ['race', 'gender', 'age', 'admission_type_id', 'discharge_disposition_id', 'admission_source_id', 'max_glu_serum', 'A1Cresult', 'change', 'diabetesMed']\n",
    "data = cudf.get_dummies(data, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "# Encode the target variable\n",
    "data['readmitted'] = data['readmitted'].applymap(lambda x: 1 if x == '<30' else 0)\n",
    "\n",
    "# Define features and target variable\n",
    "X = data.drop(columns=['readmitted', 'encounter_id', 'patient_nbr'])\n",
    "y = data['readmitted']\n",
    "\n",
    "# Encode any remaining non-numeric columns\n",
    "non_numeric_columns = X.select_dtypes(include=['object']).columns\n",
    "for col in non_numeric_columns:\n",
    "    X[col] = X[col].astype('category').cat.codes\n",
    "\n",
    "# Split the dataset into training and validation sets using cuML\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data and apply SMOTE\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(cp.asnumpy(X_train_scaled), cp.asnumpy(y_train))\n",
    "\n",
    "X_train_smote = cp.array(X_train_smote)\n",
    "y_train_smote = cp.array(y_train_smote)\n",
    "\n",
    "# Model evaluation function\n",
    "def evaluate_model(model, X_valid, y_valid):\n",
    "    y_pred = model.predict(X_valid)\n",
    "    y_pred = cp.asnumpy(y_pred)\n",
    "    y_valid = cp.asnumpy(y_valid)\n",
    "    accuracy = accuracy_score(y_valid, y_pred)\n",
    "    roc_auc = roc_auc_score(y_valid, y_pred)\n",
    "    precision = precision_score(y_valid, y_pred)\n",
    "    recall = recall_score(y_valid, y_pred)\n",
    "    f1 = f1_score(y_valid, y_pred)\n",
    "    return accuracy, roc_auc, precision, recall, f1\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    #'Logistic Regression': LogisticRegression(max_iter=500),\n",
    "    #'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    #'XGBoost': xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42, tree_method='gpu_hist'),\n",
    "    'SVM': SVC(kernel='linear', probability=True, random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "results = []\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train_smote, y_train_smote)\n",
    "    accuracy, roc_auc, precision, recall, f1 = evaluate_model(model, X_valid_scaled, y_valid)\n",
    "    results.append([model_name, accuracy, roc_auc, precision, recall, f1])\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame(results, columns=['Model', 'Accuracy', 'ROC-AUC', 'Precision', 'Recall', 'F1'])\n",
    "print(results_df)\n",
    "\n",
    "# Hyperparameter tuning for SVM using cuML\n",
    "param_distributions_svm = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# You may need to implement your own RandomizedSearchCV or use the existing one from scikit-learn with n_jobs set to 1\n",
    "# because cuML doesn't have a direct implementation of RandomizedSearchCV.\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "grid_svm = RandomizedSearchCV(SVC(probability=True, random_state=42), param_distributions_svm, n_iter=20, cv=5, scoring='roc_auc', random_state=42)\n",
    "grid_svm.fit(cp.asnumpy(X_train_smote), cp.asnumpy(y_train_smote))\n",
    "\n",
    "# Best parameters and score for SVM\n",
    "print(\"Best parameters for SVM:\", grid_svm.best_params_)\n",
    "print(\"Best ROC-AUC score for SVM:\", grid_svm.best_score_)\n",
    "\n",
    "# Evaluate on the validation set\n",
    "best_svm = grid_svm.best_estimator_\n",
    "accuracy, roc_auc, precision, recall, f1 = evaluate_model(best_svm, X_valid_scaled, y_valid)\n",
    "\n",
    "print(\"SVM with Best Parameters:\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"ROC-AUC: {roc_auc}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1: {f1}\")\n",
    "\n",
    "conf_matrix_svm_best = confusion_matrix(cp.asnumpy(y_valid), cp.asnumpy(best_svm.predict(X_valid_scaled)))\n",
    "sns.heatmap(conf_matrix_svm_best, annot=True, fmt='d')\n",
    "plt.title(\"SVM with Best Parameters Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44ca992-cb8c-48d4-ab1c-ec65396b99ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
